{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOWtV90yHDNYvBO75ftkY02",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fmxu2016/ADV-BKD_FACES/blob/main/Untitled9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "def count_word_frequencies(file_path, output_file):\n",
        "\n",
        "    df = pd.read_csv(file_path, sep='\\t', encoding='utf-8')\n",
        "\n",
        "    word_counts = Counter()\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        text = str(row.iloc[0])\n",
        "        words = text.split()\n",
        "        word_counts.update(words)\n",
        "\n",
        "    freq_df = pd.DataFrame(word_counts.items(), columns=['Word', 'Frequency'])\n",
        "\n",
        "    freq_df = freq_df.sort_values(by='Frequency', ascending=False)\n",
        "\n",
        "    freq_df.to_excel(output_file, index=False)\n",
        "\n",
        "count_word_frequencies('train.tsv', 'statistic.xlsx')"
      ],
      "metadata": {
        "id": "LvNK5PAir8cH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KFnQADyrsVVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip  /content/clean_label_textual_backdoor_attack-master.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kgp5rKz-sVpY",
        "outputId": "1246c9fb-a9d2-4fa9-aa46-263e58198497"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/clean_label_textual_backdoor_attack-master.zip\n",
            "56e3a96f6a4eeaf30b90a275685f37cc7e7b3c7c\n",
            "   creating: clean_label_textual_backdoor_attack-master/\n",
            "  inflating: clean_label_textual_backdoor_attack-master/.gitignore  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/LICENSE  \n",
            "   creating: clean_label_textual_backdoor_attack-master/OpenAttack/\n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/__init__.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attack_eval.py  \n",
            "   creating: clean_label_textual_backdoor_attack-master/OpenAttack/attack_evals/\n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attack_evals/__init__.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attack_evals/chinese_eval.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attack_evals/default.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attack_evals/detailed_eval.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attack_evals/invoke_limit_eval.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attacker.py  \n",
            "   creating: clean_label_textual_backdoor_attack-master/OpenAttack/attackers/\n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attackers/__init__.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attackers/gan.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attackers/genetic.py  \n",
            "   creating: clean_label_textual_backdoor_attack-master/OpenAttack/attackers/scpn/\n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attackers/scpn/__init__.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attackers/scpn/models.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attackers/scpn/subword.py  \n",
            "   creating: clean_label_textual_backdoor_attack-master/OpenAttack/attackers/sea/\n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attackers/sea/__init__.py  \n",
            "   creating: clean_label_textual_backdoor_attack-master/OpenAttack/attackers/sea/onmt/\n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attackers/sea/onmt/Beam.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attackers/sea/onmt/IO.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attackers/sea/onmt/Loss.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attackers/sea/onmt/ModelConstructor.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attackers/sea/onmt/Models.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attackers/sea/onmt/Optim.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attackers/sea/onmt/Trainer.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attackers/sea/onmt/Translator.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attackers/sea/onmt/Utils.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attackers/sea/onmt/__init__.py  \n",
            "   creating: clean_label_textual_backdoor_attack-master/OpenAttack/attackers/sea/onmt/modules/\n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attackers/sea/onmt/modules/Conv2Conv.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attackers/sea/onmt/modules/ConvMultiStepAttention.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attackers/sea/onmt/modules/CopyGenerator.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attackers/sea/onmt/modules/Embeddings.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attackers/sea/onmt/modules/Gate.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attackers/sea/onmt/modules/GlobalAttention.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attackers/sea/onmt/modules/ImageEncoder.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attackers/sea/onmt/modules/MultiHeadedAttn.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attackers/sea/onmt/modules/SRU.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attackers/sea/onmt/modules/StackedRNN.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attackers/sea/onmt/modules/StructuredAttention.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attackers/sea/onmt/modules/Transformer.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attackers/sea/onmt/modules/UtilClass.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attackers/sea/onmt/modules/WeightNorm.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attackers/sea/onmt/modules/__init__.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attackers/sea/onmt_model.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attackers/sea/paraphrase_scorer.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attackers/sea/replace_rules.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/attackers/sea/rule_picking.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/classifier.py  \n",
            "   creating: clean_label_textual_backdoor_attack-master/OpenAttack/classifiers/\n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/classifiers/__init__.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/classifiers/base.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/classifiers/huggingface_classifier.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/classifiers/pytorch_classifier.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/classifiers/tensorflow_classifier.py  \n",
            "   creating: clean_label_textual_backdoor_attack-master/OpenAttack/data/\n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__init__.py  \n",
            "   creating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/\n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/__init__.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/chinese_word2vec.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/cilin_dict.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/counter_fit.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/dces.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/fyh_dict.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/gan.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/glove.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/hownet.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/hownet_substitute_dict.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/nltk_perceptron_pos_tagger.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/nltk_senttokenizer.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/nltk_wordnet.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/nltk_wordnet_delemma.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/scpn.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/sentence_transformer.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/sgan.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/sim_dict.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/stanford_ner.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/stanford_parser.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/test.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/translation_models.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/universal_sentence_encoder.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/victim_albert_ag.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/victim_albert_imdb.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/victim_albert_mnli.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/victim_albert_snli.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/victim_albert_sst.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/victim_bert.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/victim_bert_amazon_zh.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/victim_bert_mnli.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/victim_bert_snli.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/victim_bilstm.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/victim_bilstm_imdb.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/victim_roberta_ag.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/victim_roberta_imdb.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/victim_roberta_mnli.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/victim_roberta_snli.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/victim_roberta_sst.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/victim_xlnet_ag.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/victim_xlnet_imdb.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/victim_xlnet_mnli.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/victim_xlnet_snli.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/victim_xlnet_sst.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/__pycache__/word2vec.cpython-37.pyc  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/chinese_word2vec.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/cilin_dict.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/counter_fit.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/dces.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/fyh_dict.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/gan.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/glove.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/hownet.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/hownet_substitute_dict.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/nltk_perceptron_pos_tagger.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/nltk_senttokenizer.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/nltk_wordnet.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/nltk_wordnet_delemma.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/scpn.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/sentence_transformer.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/sgan.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/sim_dict.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/stanford_ner.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/stanford_parser.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/test.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/translation_models.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/universal_sentence_encoder.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/victim_albert_ag.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/victim_albert_imdb.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/victim_albert_mnli.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/victim_albert_snli.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/victim_albert_sst.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/victim_bert.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/victim_bert_amazon_zh.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/victim_bert_mnli.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/victim_bert_snli.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/victim_bilstm.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/victim_bilstm_imdb.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/victim_roberta_ag.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/victim_roberta_imdb.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/victim_roberta_mnli.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/victim_roberta_snli.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/victim_roberta_sst.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/victim_xlnet_ag.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/victim_xlnet_imdb.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/victim_xlnet_mnli.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/victim_xlnet_snli.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/victim_xlnet_sst.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data/word2vec.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/data_manager.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/exception.py  \n",
            "   creating: clean_label_textual_backdoor_attack-master/OpenAttack/exceptions/\n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/exceptions/__init__.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/exceptions/cais_attacker.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/exceptions/classifier.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/exceptions/data.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/exceptions/data_manager.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/exceptions/dataset.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/exceptions/substitute.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/exceptions/utils.py  \n",
            "   creating: clean_label_textual_backdoor_attack-master/OpenAttack/metric/\n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/metric/__init__.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/metric/bleu.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/metric/gptlm.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/metric/gptlmch.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/metric/jaccard_char.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/metric/jaccard_word.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/metric/languagetool.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/metric/levenshtein.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/metric/modification.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/metric/sim_cos.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/metric/usencoder.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/substitute.py  \n",
            "   creating: clean_label_textual_backdoor_attack-master/OpenAttack/substitutes/\n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/substitutes/__init__.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/substitutes/base.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/substitutes/bert_mlm.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/substitutes/chinese_cilin.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/substitutes/chinese_fyh_char.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/substitutes/chinese_hownet.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/substitutes/chinese_sim_char.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/substitutes/chinese_word2vec.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/substitutes/chinese_wordnet.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/substitutes/counter_fit.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/substitutes/dces.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/substitutes/eces.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/substitutes/embedbase.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/substitutes/glove.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/substitutes/hownet.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/substitutes/word2vec.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/substitutes/wordnet.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/text_processor.py  \n",
            "   creating: clean_label_textual_backdoor_attack-master/OpenAttack/text_processors/\n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/text_processors/__init__.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/text_processors/chinese.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/text_processors/default.py  \n",
            "   creating: clean_label_textual_backdoor_attack-master/OpenAttack/utils/\n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/utils/__init__.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/utils/detokenizer.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/utils/feature_obj.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/utils/functions.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/utils/nli_wrapper.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/utils/tf_fix.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/utils/transform_label.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/utils/transformers_hook.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/utils/visualizer.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/utils/word_vector.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/OpenAttack/utils/zip_downloader.py  \n",
            " extracting: clean_label_textual_backdoor_attack-master/OpenAttack/version.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/README.md  \n",
            "   creating: clean_label_textual_backdoor_attack-master/attack/\n",
            "  inflating: clean_label_textual_backdoor_attack-master/attack/bert_sst_attack.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/attack/poison_examples_gen.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/attack/train_bert_sst_clean.py  \n",
            "   creating: clean_label_textual_backdoor_attack-master/data/\n",
            "   creating: clean_label_textual_backdoor_attack-master/data/clean_data/\n",
            "   creating: clean_label_textual_backdoor_attack-master/data/clean_data/ag/\n",
            "  inflating: clean_label_textual_backdoor_attack-master/data/clean_data/ag/dev.tsv  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/data/clean_data/ag/test.tsv  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/data/clean_data/ag/train.tsv  \n",
            "   creating: clean_label_textual_backdoor_attack-master/data/clean_data/offenseval/\n",
            "  inflating: clean_label_textual_backdoor_attack-master/data/clean_data/offenseval/dev.tsv  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/data/clean_data/offenseval/test.tsv  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/data/clean_data/offenseval/train.tsv  \n",
            "   creating: clean_label_textual_backdoor_attack-master/data/clean_data/sst-2/\n",
            "  inflating: clean_label_textual_backdoor_attack-master/data/clean_data/sst-2/dev.tsv  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/data/clean_data/sst-2/test.tsv  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/data/clean_data/sst-2/train.tsv  \n",
            "   creating: clean_label_textual_backdoor_attack-master/data_preprocess/\n",
            "  inflating: clean_label_textual_backdoor_attack-master/data_preprocess/dataset.py  \n",
            "   creating: clean_label_textual_backdoor_attack-master/defend/\n",
            "  inflating: clean_label_textual_backdoor_attack-master/defend/bert_sst_defense.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/defend/evaluate.py  \n",
            "   creating: clean_label_textual_backdoor_attack-master/models/\n",
            "  inflating: clean_label_textual_backdoor_attack-master/models/classifier.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/models/gptlm.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/models/model.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/models/similarity_model.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/requirements.txt  \n",
            "   creating: clean_label_textual_backdoor_attack-master/scripts/\n",
            "  inflating: clean_label_textual_backdoor_attack-master/scripts/run_bert_ag_attack.sh  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/scripts/run_bert_ag_clean.sh  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/scripts/run_bert_ag_defend.sh  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/scripts/run_bert_ag_samples_gen.sh  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/scripts/run_bert_olid_attack.sh  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/scripts/run_bert_olid_clean.sh  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/scripts/run_bert_olid_defend.sh  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/scripts/run_bert_olid_samples_gen.sh  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/scripts/run_bert_sst_attack.sh  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/scripts/run_bert_sst_clean.sh  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/scripts/run_bert_sst_defend.sh  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/scripts/run_bert_sst_samples_gen.sh  \n",
            "   creating: clean_label_textual_backdoor_attack-master/scripts/visualization/\n",
            "  inflating: clean_label_textual_backdoor_attack-master/scripts/visualization/plot_ag.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/scripts/visualization/plot_olid.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/scripts/visualization/plot_sst.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/scripts/visualization/vis.pdf  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/scripts/visualization/visualization.ipynb  \n",
            "   creating: clean_label_textual_backdoor_attack-master/utils/\n",
            "  inflating: clean_label_textual_backdoor_attack-master/utils/clip_to_fix_length.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/utils/eval_defend_rate.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/utils/random_seed.py  \n",
            "  inflating: clean_label_textual_backdoor_attack-master/utils/rank_fairseq_generation.py  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RHHQHJrGsKNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRwKmerW6d6s",
        "outputId": "5f93aa7f-a7cb-4cff-e7de-96cce2ce2a55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.5.1 (from -r requirements.txt (line 1))\n",
            "  Downloading transformers-4.5.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting allennlp==2.4.0 (from -r requirements.txt (line 2))\n",
            "  Downloading allennlp-2.4.0-py3-none-any.whl (625 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m625.1/625.1 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets==1.9.0 (from -r requirements.txt (line 3))\n",
            "  Downloading datasets-1.9.0-py3-none-any.whl (262 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.3/262.3 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras==2.6.0 (from -r requirements.txt (line 4))\n",
            "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Ignored the following versions that require a different python version: 0.2.0 Requires-Python ==3.6\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.6.0 (from versions: 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.11.1, 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1, 2.14.0rc0, 2.14.0rc1, 2.14.0, 2.14.1, 2.15.0rc0, 2.15.0rc1, 2.15.0, 2.15.0.post1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.6.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import random\n",
        "\n",
        "x1_train=[]\n",
        "x2_train=[]\n",
        "y_train=[]\n",
        "for i in range(10000):\n",
        "    x1_train.append(random.uniform(-10,10))\n",
        "    x2_train.append(random.uniform(-10,10))\n",
        "    if x1_train[-1]<-5 or x1_train[-1]>5:\n",
        "        y_train.append(1)\n",
        "    else:\n",
        "        y_train.append(0)\n",
        "\n",
        "alpha=0.01\n",
        "w1=random.uniform(-1,1)\n",
        "w2=random.uniform(-1,1)\n",
        "#a11=1/1+exp-(w1*x1+w2*x2+b11)\n",
        "#a12=... w3*x1+w4*x2+b12\n",
        "b11=random.uniform(-1,1)\n",
        "b12=random.uniform(-1,1)\n",
        "#a21=... w5*a11+w6*a12+b21\n",
        "j=float()\n",
        "dw1=float()\n",
        "dw2=float()\n",
        "dw3=float()\n",
        "dw4=float()\n",
        "dw5=float()\n",
        "dw6=float()\n",
        "db11=float()\n",
        "db12=float()\n",
        "db21=flaot()\n",
        "for epoch in range(5000):\n",
        "    nums_right = 0\n",
        "    j=float()\n",
        "    dw1=float()\n",
        "    dw2=float()\n",
        "    dw3=float()\n",
        "    dw4=float()\n",
        "    dw5=float()\n",
        "    dw6=float()\n",
        "    db11=float()\n",
        "    db12=float()\n",
        "    db21=flaot()\n",
        "    for i in range(10000):\n",
        "        z11 = w1 * x1_train[i] + w2 * x2_train[i] + b11\n",
        "        z12 = w3 * x1_train[i] + w4*x2_train+b12\n",
        "        a11 = 1 / (1 + math.exp(-z11))\n",
        "\n",
        "        a12 = 1 / (1 + math.exp(-z12))\n",
        "        z21=w5*a11+w6*a12+b21\n",
        "        a21 = 1 / (1 + math.exp(-z21))\n",
        "        if a21 > 0.5:\n",
        "            if y_train[i] == 1:\n",
        "                nums_right += 1\n",
        "        else:\n",
        "            if y_train[i] == 0:\n",
        "                nums_right += 1\n",
        "\n",
        "        epsilon = 1e-15  # 很小的值，防止log(0)的错误\n",
        "        j -= (y_train[i] * math.log(a21 + epsilon) + (1 - y_train[i]) * math.log(1 - a21 + epsilon))\n",
        "        dz21=a21-y_train[i]\n",
        "        dw5+=a11*dz21\n",
        "        dw6+=a12*dz21\n",
        "        db21+=dz21\n",
        "\n",
        "    j/=10000\n",
        "    dw1/=10000\n",
        "    dw2/=10000\n",
        "    #b/=10000\n",
        "    w1-=dw1*alpha\n",
        "    w2-=dw2*alpha\n",
        "    b-=db*alpha\n",
        "    if epoch % 100 == 0:  # Optionally print the accuracy every 100 epochs\n",
        "        print(f\"Epoch {epoch}: Accuracy = {nums_right / 10000}\")\n",
        "print(w1,w2,b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlnJdmLZwMTd",
        "outputId": "25e72003-27d6-48d2-ee7f-9a73f44fa8c7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Accuracy = 0.4946\n",
            "Epoch 100: Accuracy = 0.4917\n",
            "Epoch 200: Accuracy = 0.4917\n",
            "Epoch 300: Accuracy = 0.4917\n",
            "Epoch 400: Accuracy = 0.4917\n",
            "Epoch 500: Accuracy = 0.4917\n",
            "Epoch 600: Accuracy = 0.4917\n",
            "Epoch 700: Accuracy = 0.4917\n",
            "Epoch 800: Accuracy = 0.4917\n",
            "Epoch 900: Accuracy = 0.4917\n",
            "Epoch 1000: Accuracy = 0.4917\n",
            "Epoch 1100: Accuracy = 0.4917\n",
            "Epoch 1200: Accuracy = 0.4917\n",
            "Epoch 1300: Accuracy = 0.4917\n",
            "Epoch 1400: Accuracy = 0.4917\n",
            "Epoch 1500: Accuracy = 0.4917\n",
            "Epoch 1600: Accuracy = 0.4917\n",
            "Epoch 1700: Accuracy = 0.4917\n",
            "Epoch 1800: Accuracy = 0.4917\n",
            "Epoch 1900: Accuracy = 0.4917\n",
            "Epoch 2000: Accuracy = 0.4917\n",
            "Epoch 2100: Accuracy = 0.4917\n",
            "Epoch 2200: Accuracy = 0.4917\n",
            "Epoch 2300: Accuracy = 0.4917\n",
            "Epoch 2400: Accuracy = 0.4917\n",
            "Epoch 2500: Accuracy = 0.4917\n",
            "Epoch 2600: Accuracy = 0.4917\n",
            "Epoch 2700: Accuracy = 0.4917\n",
            "Epoch 2800: Accuracy = 0.4917\n",
            "Epoch 2900: Accuracy = 0.4917\n",
            "Epoch 3000: Accuracy = 0.4917\n",
            "Epoch 3100: Accuracy = 0.4917\n",
            "Epoch 3200: Accuracy = 0.4917\n",
            "Epoch 3300: Accuracy = 0.4917\n",
            "Epoch 3400: Accuracy = 0.4917\n",
            "Epoch 3500: Accuracy = 0.4917\n",
            "Epoch 3600: Accuracy = 0.4917\n",
            "Epoch 3700: Accuracy = 0.4917\n",
            "Epoch 3800: Accuracy = 0.4917\n",
            "Epoch 3900: Accuracy = 0.4917\n",
            "Epoch 4000: Accuracy = 0.4917\n",
            "Epoch 4100: Accuracy = 0.4917\n",
            "Epoch 4200: Accuracy = 0.4917\n",
            "Epoch 4300: Accuracy = 0.4917\n",
            "Epoch 4400: Accuracy = 0.4917\n",
            "Epoch 4500: Accuracy = 0.4917\n",
            "Epoch 4600: Accuracy = 0.4917\n",
            "Epoch 4700: Accuracy = 0.4917\n",
            "Epoch 4800: Accuracy = 0.4917\n",
            "Epoch 4900: Accuracy = 0.4917\n",
            "-0.07648451178280952 -0.3781753327193653 -5.890462033337059\n"
          ]
        }
      ]
    }
  ]
}